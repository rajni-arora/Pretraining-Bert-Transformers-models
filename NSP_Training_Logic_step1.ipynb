{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOfNFIkNVSbyHt4P3cObIU+",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rajni-arora/Pretraining-Bert-Transformers-models/blob/main/NSP_Training_Logic_step1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next sentence prediction (NSP) is the other side of pretraining for BERT. It consists of taking two sentences, A and B - and attempting to guess (classification) whether sentence B comes after sentence A.\n",
        "\n",
        "So, where MLM allowed us to encourage BERT to build up a contextual understanding between words - NSP encourages BERT to learn longer term contextual relationships between sentences rather than words.\n",
        "\n",
        "Let's take a look at how this works in code. First, we import and initialize everything we need."
      ],
      "metadata": {
        "id": "7KEmvvBbM7hF"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a9pZziF9M16W"
      },
      "outputs": [],
      "source": [
        "!pip install transformers"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import BertTokenizer, BertForNextSentencePrediction\n",
        "import torch"
      ],
      "metadata": {
        "id": "inHYc2_kNBGb"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "model = BertForNextSentencePrediction.from_pretrained('bert-base-uncased')\n",
        "\n",
        "text = (\"After Abraham Lincoln won the November 1860 presidential election on an \"\n",
        "        \"anti-slavery platform, an initial seven slave states declared their \"\n",
        "        \"secession from the country to form the Confederacy. War broke out in \"\n",
        "        \"April 1861 when secessionist forces attacked Fort Sumter in South \"\n",
        "        \"Carolina, just over a month after Lincoln's inauguration.\")"
      ],
      "metadata": {
        "id": "UOKMp-O4NB48"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = tokenizer(text, return_tensors='pt')\n",
        "outputs = model(**inputs)\n",
        "outputs.keys()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3Xt0Cn_EaT78",
        "outputId": "6a66b541-83a8-4091-bf38-8e5fe70f9319"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "odict_keys(['logits'])"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The logits tensor is our NSP output prediction, which looks like:"
      ],
      "metadata": {
        "id": "P78FAhp4afAP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "outputs.logits"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WSqTIjVUaT3-",
        "outputId": "dde93e91-f1fb-43d2-889c-802d53501745"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 4.4646, -3.6635]], grad_fn=<AddmmBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Apply softmax to convert these logits into a probability distribution."
      ],
      "metadata": {
        "id": "ypKdAGwcakO0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "probs = torch.nn.functional.softmax(outputs.logits, dim=-1)\n",
        "probs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RUzajWNsaT1_",
        "outputId": "ca120b4c-64ea-4cdd-bc78-abb9987e6e1c"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[9.9970e-01, 2.9502e-04]], grad_fn=<SoftmaxBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.argmax(probs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cQFFFqrKaTyK",
        "outputId": "3d7255a9-8623-414d-f465-6c989a717628"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0)"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We are getting 0, which is IsNextSentence - however, we haven't actually specified two sentences - so this prediction is meaningless.\n",
        "\n",
        "There are two parts we're missing. We need to specify two sentences in our input_ids tensor - and we need to create the labels tensor too.\n",
        "\n",
        "Let's start by splitting the two sentences."
      ],
      "metadata": {
        "id": "JjZ-N8Rbatib"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text = (\"After Abraham Lincoln won the November 1860 presidential election on an \"\n",
        "        \"anti-slavery platform, an initial seven slave states declared their \"\n",
        "        \"secession from the country to form the Confederacy.\")\n",
        "text2 = (\"War broke out in April 1861 when secessionist forces attacked Fort \"\n",
        "         \"Sumter in South Carolina, just over a month after Lincoln's \"\n",
        "         \"inauguration.\")"
      ],
      "metadata": {
        "id": "pwct1gENaTwi"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = tokenizer(text, text2, return_tensors='pt')"
      ],
      "metadata": {
        "id": "VR94ayckawl3"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inputs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sPYK9txga0uP",
        "outputId": "8d63a8bb-a427-41f9-b29d-1514a971cc67"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'input_ids': tensor([[  101,  2044,  8181,  5367,  2180,  1996,  2281,  7313,  4883,  2602,\n",
              "          2006,  2019,  3424,  1011,  8864,  4132,  1010,  2019,  3988,  2698,\n",
              "          6658,  2163,  4161,  2037, 22965,  2013,  1996,  2406,  2000,  2433,\n",
              "          1996, 18179,  1012,   102,  2162,  3631,  2041,  1999,  2258,  6863,\n",
              "          2043, 22965,  2923,  2749,  4457,  3481,  7680,  3334,  1999,  2148,\n",
              "          3792,  1010,  2074,  2058,  1037,  3204,  2044,  5367,  1005,  1055,\n",
              "         17331,  1012,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Because we tokenized the two sentences seperately, our tokenizer will deal it a little differently. First, we can see the SEP token in the input_ids tensor with token id 102 - this marks the boundary between sentence A and sentence B.\n",
        "\n",
        "Second, we can distinguish between sentences from the token_type_ids - sentence A tokens are assigned a 0, whereas sentence B tokens are assigned a 1 token.\n",
        "\n",
        "Now, we still need to add our labels tensor - but how should it be formatted? Well, we use a torch.LongTensor format, and it must contain a single value [0] if sentence B is the next sentence, else it should be [1]. Here, sentence B is the next sentence so we set it to [0]."
      ],
      "metadata": {
        "id": "M3RVC7kba42J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "labels = torch.LongTensor([0])\n",
        "labels"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nZBXNKa2a2LF",
        "outputId": "d8e3ffc8-7867-457f-f3e6-5caa5443804b"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0])"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we process everything as we did before, including our labels tensor."
      ],
      "metadata": {
        "id": "y5los0Cea-tA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "outputs = model(**inputs, labels=labels)\n",
        "outputs.keys()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5hB4VzyBa7zJ",
        "outputId": "d9533d39-324b-4e76-dc5d-66cc21fcc290"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "odict_keys(['loss', 'logits'])"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "outputs.loss"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R_sYZxbtbAze",
        "outputId": "7315b8fc-fab3-45ee-a1e6-66372e136198"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(3.2186e-06, grad_fn=<NllLossBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we return the loss tensor - which we use for training our model with NSP."
      ],
      "metadata": {
        "id": "uc6MTxEbbEgy"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6Yjf3QnTbCff"
      },
      "execution_count": 13,
      "outputs": []
    }
  ]
}